import{r as t,o as a,c as s,a as e,e as i,w as n,F as d,b as o,d as c}from"./app.749a123f.js";import{_ as l}from"./plugin-vue_export-helper.21dcd24c.js";const h={},u=e("blockquote",null,[e("p",null,[o("This is going to be "),e("strong",null,"a lot of moving parts"),o(". This is partially by design and partially a result of rapidly changing ideas and requirements. I really can't guarantee API stability for much of this at this early stage.")])],-1),p=e("h2",{id:"icensoringprovider",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#icensoringprovider","aria-hidden":"true"},"#"),o(),e("code",null,"ICensoringProvider")],-1),m=e("blockquote",null,[e("p",null,"This is the big one")],-1),g=e("code",null,"ICensoringProvider",-1),f=o(" is the basic interface for censoring an image after it's been classified by the "),y=o("AI service"),b=o(". In general, you want to take the "),v=e("code",null,"ImageResult",-1),w=o(" from the AI and pass it to the "),_=e("code",null,"ICensoringProvider",-1),I=o(", optionally with a results parser. From there, the censoring provider will censor the image and return the censored result."),T=c('<h2 id="imagesharpcensoringprovider" tabindex="-1"><a class="header-anchor" href="#imagesharpcensoringprovider" aria-hidden="true">#</a> <code>ImageSharpCensoringProvider</code></h2><p>This is the default censoring provider for CensorCore.</p><blockquote><p>It is <strong>strongly</strong> recommended to use the <code>ImageSharpCensoringProvider</code> as your <code>ICensoringProvider</code> implementation. It has its own extensibility points for customisations.</p></blockquote><p>This provider uses ImageSharp to load and modify the image being censored, relying on &quot;censor type providers&quot; (see below) for the real work of censoring the image. The <code>ImageSharpCensoringProvider</code> will (to greatly oversimplify things), loop through the results from the AI, run any transformers (see below), run any middlewares (see below), match results against a censor type to get the required image modification (i.e the censoring bit), then apply the results of all of the above onto the image to produce a censored image.</p><p>That design of deferring the image editing does mean that censor types cannot depend on one another, but it also makes it much harder to cause accidental conflicts/cancellations.</p><h3 id="icensortypeprovider" tabindex="-1"><a class="header-anchor" href="#icensortypeprovider" aria-hidden="true">#</a> <code>ICensorTypeProvider</code></h3><p>The censor type provider is an implementation of <code>ICensorTypeProvider</code> and is responsible for the different censoring methods. For example, blurring and pixelation are two of the available providers. Each provider is passed the unmodified source image, the details of the current match, and a results parser if one is available. The provider can then (optionally) return the modification it wants to make to the image.</p><blockquote><p>There&#39;s a whole bunch of censor types included with CensorCore: blurring, pixelation, and black bar, sticker and caption overlays.</p></blockquote><p>Note that the modification is not <em>immediately</em> applied to the source image, the provider just stores it for later application.</p><h4 id="layers" tabindex="-1"><a class="header-anchor" href="#layers" aria-hidden="true">#</a> Layers</h4><p>Every provider specifies a <em>layer</em> that its modifications are made on. Providers can specify whatever layer they want, but the default is <code>0</code>. In general, only change this if your censor type is <strong>additive</strong>. Layer 0 is where all destructive or source-based edits are made (like blurs, pixelations etc), while captions and stickers (for example) are made a few layers higher since they are drawn over other censors/image features. You could also set your layer below <code>0</code>, but be aware that it may then be cancelled out by the source-based censors on layer 0.</p><h4 id="virtual-classifications" tabindex="-1"><a class="header-anchor" href="#virtual-classifications" aria-hidden="true">#</a> Virtual Classifications</h4><p>The <code>Classification</code> type includes a <code>VirtualBox</code> property that designates the current classification as &quot;virtual&quot;. Virtual classifications are matches that aren&#39;t directly based on the content at the given bounding box. This <em>usually</em> indicates that the content to be censored is at a related location (such as the location after any relevant offsets or transforms are applied). If your provider is limited in capabilities (like not handling angled results) then skip virtual classifications to avoid censoring irrelevant areas of the images.</p><h3 id="iresultstransformer" tabindex="-1"><a class="header-anchor" href="#iresultstransformer" aria-hidden="true">#</a> <code>IResultsTransformer</code></h3><blockquote><p>Use this with caution! If an <code>IResultsTransformer</code> doesn&#39;t return a match, it is <strong>dropped</strong> from the censoring session.</p></blockquote><p>The <code>IResultsTransformer</code> API is useful for transforming the results from the AI before the censoring begins, for changes that don&#39;t need the image data. For example, an <code>IResultsTransformer</code> can add new matches based on existing AI matches, or add/remove matches to be passed to the censoring providers. For a more grounded example, one of the bundled transformers applies a flat scaling to increase/decrease the size of the matches returned by the AI.</p><p>While the behaviour is controlled by the <code>ICensoringProvider</code> in use, it&#39;s generally safe to assume that transformers will be run in the order they are registered. That being said, it&#39;s best not to <strong>rely</strong> on that behaviour.</p><p>A no-op transformer can simply return the match collection it was passed. Additionally, the ResultsTransformer is currently <strong>synchronous</strong>. This may be changed in a future release.</p><h3 id="icensoringmiddleware" tabindex="-1"><a class="header-anchor" href="#icensoringmiddleware" aria-hidden="true">#</a> <code>ICensoringMiddleware</code></h3><blockquote><p>Use this with caution! This API is very easy to get wrong, and is <em>usually</em> only a last resort for niche use cases.</p></blockquote><p>As the name implies, censoring middleware is an abstraction for more complex and niche censoring needs that need access to more of the censoring session. They can also add new mutations to the image but <em>cannot</em> modify/remove other censors. Since they are executed sequentially and block censoring until completed, you should try and keep middleware as fast as possible. Currently, it is only used for censoring matches not supported by NudeNet.</p><h2 id="iresultparser" tabindex="-1"><a class="header-anchor" href="#iresultparser" aria-hidden="true">#</a> <code>IResultParser</code></h2><p>The result parser is a special type that should be provided by <em>consumers</em> of CensorCore. The result parser can be injected into the <code>ImageSharpCensoringProvider</code> or passed per-request to the current censoring provider. The result parser is what the censor type providers query to tweak whether the censoring should be applied and/or how aggressively.</p>',23);function k(x,C){const r=t("RouterLink");return a(),s(d,null,[u,p,m,e("p",null,[g,f,i(r,{to:"/ai-components.html"},{default:n(()=>[y]),_:1}),b,v,w,_,I]),T],64)}var A=l(h,[["render",k]]);export{A as default};
